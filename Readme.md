# Нейросеть для автодополнения текстов.

В данном проекте рассмотренно создание сети на базе LSTM для автодоплнения текста. Проект содержит следующие этапы:

1. На первом этапенами был проанализирован и почищен датасет товитов было установленно, что как правило твиты не превышают 35 слов. так же нами была проведена токенизация текста и выделены тренировочные, валидационные и тестовые данные.
2. На втором этапе были созданны кастомные классы датасетов и функция collate_fn, такж был создан класс модели на базе архитектуры LSTM. Модель была обучена и проверено качество генерации текста. Модель можно попробовать доработать (возможно, уменьшение lr позволит сойтись до более низкого значения лосса, хотя и увеличит время обучения; так же стоит попробовать боле жёстко почистить исходные данные и убрать повторяющиеся знаки препинания, что позволит модели реже зацикливаться).
3. На третьем этапе была рассмотрена предобученная модель архитектуры трансформера, она генерирует более связный текст и на тестовых данных показала себя немного лучше чем LSTM, хотя она тоже иногда галлюционировала. 

## Структура проекта.
- В корневой директории находится ноутбук с решением solution.ipynb содержит исследование и код по предобработке данных, созданию и обучению сети.
- Для даненых рекомендуется создать папку data либо внести соответствующие исправления в пути в начале проекта.
- Для сохранения модели рекомендуется создать папку models либо внести соответствующие исправления в пути в начале проекта.
